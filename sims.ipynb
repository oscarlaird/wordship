{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "Embedding for \"king\":\n",
      " [ 3.1542e-01 -3.5068e-01  4.2923e-01 -5.3825e-01 -1.8480e-01 -3.1082e-01\n",
      "  2.9196e-01 -7.1030e-01 -2.3867e-01  1.8471e+00 -3.6446e-01 -5.1282e-01\n",
      "  1.2210e-01  3.8909e-01 -7.3204e-02  3.5462e-02  3.3289e-01  6.6466e-01\n",
      "  2.7175e-02  4.2021e-01 -1.4520e-01  3.7991e-01 -6.0520e-01  1.0695e-01\n",
      " -6.4716e-01 -1.0739e-02 -3.9754e-01  3.8857e-01 -2.0134e-01  6.9813e-01\n",
      " -3.2411e-01  7.3085e-01 -1.0930e-01 -2.3511e-01  1.8482e-01 -1.1595e-01\n",
      " -7.1003e-01 -2.2974e-01 -4.1979e-01  8.1004e-03 -1.0504e-01 -4.4802e-01\n",
      " -7.3928e-02 -4.2380e-01  2.8482e-01 -7.4517e-02  9.8161e-02  6.4602e-01\n",
      " -2.5832e-01 -2.0452e-02 -6.6863e-02  5.1501e-01  1.6758e-01  1.2329e-01\n",
      "  1.9636e-01  1.1958e-01 -1.8296e-01 -1.4325e-01 -2.7758e-01  5.0597e-02\n",
      " -6.6122e-02 -1.8920e-01  3.3300e-01  2.5319e-01  6.6355e-01  6.6735e-01\n",
      "  4.9969e-01  1.5481e-01 -8.4247e-02 -2.2947e-01 -6.8367e-01 -2.9783e-01\n",
      " -1.8651e-01 -4.7121e-01  1.8272e-01 -3.2604e-01 -6.8030e-02  7.0073e-01\n",
      "  3.3159e-01  7.0393e-02 -7.6987e-01  5.9069e-01  2.0592e-01  1.7976e-01\n",
      "  6.9525e-03  5.7855e-02  7.2047e-01 -7.7249e-01 -5.4188e-01 -1.2189e-01\n",
      " -3.1734e-03 -1.5960e-01  1.6970e-01 -1.2546e-01  8.7069e-01 -4.6478e-01\n",
      " -1.9302e-01 -4.5618e-01 -1.5419e-01  8.1190e-01 -2.0544e-01  3.9454e-01\n",
      " -3.1178e-01 -6.4318e-02 -4.4443e-02 -5.8338e-01 -1.4792e-01  1.7083e-02\n",
      "  8.3239e-01 -1.1280e-01  5.7826e-02  1.7024e-01 -1.3635e-01 -2.8894e-01\n",
      " -4.0590e-01 -5.0685e-02  4.9856e-01  6.0885e-02  1.9437e-01 -1.9811e-01\n",
      " -2.2335e-01 -2.5909e-02  3.9846e-01  4.4087e-01  2.3195e-02  9.8666e-02\n",
      " -1.3004e-01 -2.0339e-01 -4.2958e-01 -7.9760e-03 -3.2016e-01 -4.1094e-01\n",
      " -1.0304e-01 -7.5565e-01  1.7748e-02 -2.0037e-01  1.7185e-01  2.1787e-01\n",
      " -3.1685e-01  2.2068e-02 -2.5559e+00 -9.9115e-02  1.8434e-01  1.2448e-01\n",
      " -5.9413e-02 -4.5649e-02  7.9018e-01  2.4556e-01 -1.5059e-02 -7.8996e-01\n",
      "  2.9087e-01 -3.9419e-01  3.7617e-01  1.5718e-01  5.1356e-01 -3.4219e-01\n",
      "  5.0628e-02 -3.3254e-01 -1.4157e-01  3.3355e-01  4.4398e-01 -2.5451e-01\n",
      " -3.3201e-02 -2.0958e-01  3.8870e-01 -2.4565e-01  5.2391e-01  4.3247e-01\n",
      " -4.1701e-01  2.9031e-01 -7.8001e-01  3.0100e-02 -6.1446e-02 -1.4029e-01\n",
      " -5.5354e-01 -1.9175e-01  6.7279e-01 -1.1104e-01 -3.5486e-01 -2.8601e-01\n",
      "  1.1720e-01 -4.5021e-01  1.4004e-01 -5.7484e-01 -2.2531e-01  4.1572e-01\n",
      " -1.5950e-01 -2.7877e-01  7.9785e-02  1.9120e-02 -9.8357e-01 -5.6998e-01\n",
      " -3.4023e-02  1.7382e-02 -1.7157e-02 -2.8211e-01  1.5573e-01 -1.3556e-01\n",
      " -2.6296e-01 -7.4571e-01  1.2015e-01  5.4234e-01  5.6783e-02 -7.5675e-02\n",
      "  2.1820e-01 -2.5679e-01  2.3552e-01 -2.7111e-02 -1.9342e-01 -3.1088e-01\n",
      " -1.0600e-01  4.9512e-01  5.7932e-02  3.8773e-01  9.3160e-02 -1.3782e-01\n",
      "  2.4244e-01  3.8098e-01  9.1109e-04  8.8338e-01  4.3823e-01 -7.7041e-02\n",
      "  1.1541e-01  3.4702e-01  5.9785e-01  6.7012e-01 -6.0953e-02 -4.3872e-02\n",
      " -4.0800e-01  7.5721e-01  2.4773e-01  8.8926e-02 -1.8493e-01 -5.2339e-01\n",
      "  8.5809e-02 -6.0880e-01 -7.7463e-02 -2.6829e-01 -3.9021e-01 -1.5002e-01\n",
      "  5.4297e-01 -4.1076e-01 -9.5215e-02 -2.9787e-01  1.0041e-01 -3.7774e-01\n",
      "  7.5511e-01 -4.3910e-01 -6.1722e-01 -1.0360e+00  6.9651e-01  1.4157e-01\n",
      " -4.4533e-01  3.2702e-01  3.8306e-02  2.6765e-01  5.4242e-02 -3.0242e-02\n",
      " -4.5133e-01  6.2505e-03  2.7504e-01 -5.2413e-02 -1.9870e-01 -1.7869e-01\n",
      " -2.4658e-01 -3.7369e-01  2.6174e-01  4.1482e-01 -5.9277e-01  6.1446e-02\n",
      "  6.6261e-02  1.0970e-01 -1.4388e-01 -3.2442e-01 -3.9016e-04 -2.1392e-01\n",
      "  3.2963e-01  5.0402e-01  1.3454e-01 -5.6133e-01  1.0422e+00  5.8985e-01\n",
      "  1.4473e-01  1.7745e-01  1.6160e-01  3.3230e-01  2.2909e-01  1.5774e-01\n",
      " -3.5463e-01 -4.7642e-01 -2.5822e-01  2.3677e-01 -4.0255e-01 -3.5364e-01\n",
      " -1.6697e-01  7.0677e-01  8.4272e-02  1.1427e-01  5.8221e-01 -1.0559e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_glove_embeddings(glove_file_path):\n",
    "    embeddings = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try: \n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.array(values[1:], dtype='float32')\n",
    "                embeddings[word] = vector\n",
    "            except:\n",
    "                print('error')\n",
    "    return embeddings\n",
    "\n",
    "# Load the 100-dimensional GloVe embeddings\n",
    "glove_file = './glove.840B.300d.txt'\n",
    "glove_embeddings = load_glove_embeddings(glove_file)\n",
    "\n",
    "# Check the embedding for a specific word\n",
    "word = 'king'\n",
    "print(f'Embedding for \"{word}\":\\n', glove_embeddings.get(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/.local/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import sentence_transformers\n",
    "import numpy as np\n",
    "# load the pre-trained model\n",
    "# model = sentence_transformers.SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99997216\n",
      "1.000006\n",
      "0.99999386\n",
      "1.0000012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((-0.0008725859, -0.005724415),\n",
       " (-0.0050349664, -0.0015534267),\n",
       " (0.01916994, 0.001989362),\n",
       " (0.00021105981, -0.0011858245))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tangible,Intangible,Valuable,Worthless\n",
    "# good, evil, new , old\n",
    "# ax1 = (\"simple\", \"complex\")\n",
    "ax1 = (\"hot\", \"cold\")\n",
    "# ax2 = (\"structured\", \"chaotic\")\n",
    "ax2 = (\"dry\", \"wet\")\n",
    "xrel_key = get_embedding(ax1[0]) + get_embedding(ax1[1])\n",
    "xdir_key = get_embedding(ax1[0]) - get_embedding(ax1[1])\n",
    "xdir_key = xdir_key / np.linalg.norm(xdir_key)\n",
    "yrel_key = get_embedding(ax2[0]) + get_embedding(ax2[1])\n",
    "ydir_key = get_embedding(ax2[0]) - get_embedding(ax2[1])\n",
    "ydir_key = ydir_key / np.linalg.norm(ydir_key)\n",
    "def word_to_dir(word):\n",
    "    vec = get_embedding(word)\n",
    "    print(np.linalg.norm(vec))\n",
    "    xrel = np.linalg.norm(np.dot(vec, xrel_key))\n",
    "    xdir = np.dot(vec, xdir_key)\n",
    "    yrel = np.linalg.norm(np.dot(vec, yrel_key))\n",
    "    ydir = np.dot(vec, ydir_key)\n",
    "    return xrel * xdir, yrel * ydir\n",
    "\n",
    "word_to_dir('mathematics'), word_to_dir('contentment'), word_to_dir('rage'), word_to_dir('annoyance')\n",
    "\n",
    "# pipeline\n",
    "# for each axis\n",
    "# - get relevance per word\n",
    "# - get direction per word\n",
    "# - normalize to std normal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = model2.key_to_index['/c/en/weather']\n",
    "# polnp.linalg.norm(model2.vectors[idx])\n",
    "xrel_key = yrel_key = model2.vectors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hot', 'cold') ('dry', 'wet')\n",
      "word:  blizzard\n",
      "scores:  [-0.43811432 -0.31297714]\n",
      "word:  snowy\n",
      "scores:  [-0.29574075 -0.31410658]\n",
      "word:  desert\n",
      "scores:  [0.005318   0.13764565]\n"
     ]
    }
   ],
   "source": [
    "xrels = np.abs(model2.vectors @ xrel_key)**2\n",
    "xdirs = model2.vectors @ xdir_key * xrels\n",
    "xdirs = (xdirs - np.mean(xdirs)) / np.std(xdirs)\n",
    "# xscores = xdirs * xrels\n",
    "# xscores = (xscores - np.mean(xscores))\n",
    "# xscores = xscores / np.std(xscores)\n",
    "# xscores\n",
    "# yrels = np.abs(model2.vectors @ yrel_key)**2\n",
    "ydirs = model2.vectors @ ydir_key * xrels\n",
    "# yscores = ydirs * yrels\n",
    "# yscores = (yscores - np.mean(yscores)) \n",
    "# yscores = yscores / np.std(yscores)\n",
    "# yscores\n",
    "ydirs = (ydirs - np.mean(ydirs)) / np.std(ydirs)\n",
    "# stack dirs and normalize\n",
    "dirs = np.stack((xdirs, ydirs), axis=1)\n",
    "dirs = dirs / np.linalg.norm(dirs, axis=1, keepdims=True)\n",
    "scores = dirs * (np.abs(model2.vectors @ xrel_key)**1)[:,None]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(ax1, ax2)\n",
    "# for word in (\"reform\", \"dictatorship\", \"freedom\", \"tyranny\", \"revolution\"):\n",
    "for word in (\"blizzard\", \"snowy\", \"desert\"):\n",
    "    print(\"word: \", word)\n",
    "    idx = model2.key_to_index[f'/c/en/{word}']\n",
    "    print(\"scores: \", scores[idx])\n",
    "# n.b. I think that because I normalize I don't need to use xrels and yrels\n",
    "# masculine/feminine assigns king as feminine , better just to use a simple axis like man/woman\n",
    "\n",
    "# category: facial\n",
    "# for word in (\"maniacal\")\n",
    "\n",
    "# category: politics\n",
    "# (good, evil) (wild, tame)\n",
    "# for word in (\"dog\", \"wolf\", \"werewolf\", \"freedom\", \"peace\", \"tyranny\", \"revolution\"):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.018, 0.004)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wordfreq\n",
    "# top 100\n",
    "top_100k = wordfreq.top_n_list('en', 10**5)\n",
    "top_100k.__len__()\n",
    "out = {}\n",
    "for word in top_100k:\n",
    "    try:\n",
    "        idx = model2.key_to_index[f'/c/en/{word}']\n",
    "        xscore, yscore = scores[idx]\n",
    "        out[word] = int(xscore * 1000.0)/1000.0, int(yscore * 1000.0)/1000.0\n",
    "    except:\n",
    "        # print(f\"word {word} not found\")\n",
    "        pass\n",
    "out[\"monster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg5.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m j \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdump(out, file)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# only 3 decimals of precision\n",
    "file = open(\"g5.json\", \"w\")\n",
    "j = json.dump(out, file)\n",
    "len(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"the\": [0.035, 0.11], \"to\": [0.001, 0.0], \"and\": [0.134, 0.097], \"of\": [0.008, 0.046], \"a\": [0.019, 0.007], \"in\": [0.266, 1.328], \"i\": [0.202, 0.025], \"is\": [0.646, 0.049], \"for\": [0.0, 0.0], \"that\": [0.138, 0.089], \"you\": [0.006, 0.005], \"it\": [0.0, 0.0], \"on\": [0.116, 0.385], \"with\": [0.0, 0.058], \"this\": [0.099, 0.062], \"was\": [0.018, 0.0], \"be\": [0.018, -0.004], \"as\": [0.174, -0.004], \"are\": [0.0, 0.0], \"have\": [0.144, -0.012], \"at\": [0.005, 0.001], \"he\": [0.002, 0.002], \"not\": [1.947, -0.316], \"by\": [0.007, 0.027], \"but\": [0.482, -0.238], \"from\": [0.0, 0.0], \"my\": [0.034, 0.011], \"or\": [0.119, 0.486], \"we\": [0.064, 0.049], \"an\": [0.0, 0.0], \"your\": [0.019, 0.024], \"all\": [0.028, 0.133], \"so\": [0.0, 0.0], \"his\": [-0.019, 0.083], \"they\": [0.089, 0.039], \"me\": [0.009, 0.001], \"if\": [0.1, 0.036], \"one\": [0.002, 0.003], \"can\": [0.007, 0.0], \"will\": [0.071, 0.049], \"just\": [0.704, -0.039], \"like\": [0.241, 0.025], \"about\": [0.13, 0.059], \"up\": [0.26, 0.041], \"out\": [0.01, 0.015], \"what\"'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048080556"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "w1 = \"dog\"\n",
    "w2 = \"water\"\n",
    "np.dot(get_embedding(w1), get_embedding(w2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(word):\n",
    "    return model2[f\"/c/en/{word}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model2 \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconceptnet-numberbatch-17-06-300\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mking\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Get the word vector for 'king'\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Load ConceptNet Numberbatch embeddings (300-dimensional vectors)\n",
    "import gensim.downloader as api\n",
    "model2 = api.load(\"conceptnet-numberbatch-17-06-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0831, -0.1472, -0.1256, -0.0556,  0.1531,  0.1012, -0.0885,\n",
       "        0.0704,  0.046 ,  0.0744,  0.1335, -0.038 ,  0.0213, -0.0432,\n",
       "        0.1401,  0.2077,  0.076 , -0.0194, -0.0143,  0.0101, -0.128 ,\n",
       "       -0.0642,  0.0363,  0.1289, -0.0221, -0.0652, -0.0569, -0.0522,\n",
       "       -0.0259,  0.0415,  0.0597, -0.0138, -0.0779,  0.1409, -0.0251,\n",
       "       -0.0439,  0.0218,  0.1129,  0.0074,  0.0102, -0.0129,  0.0114,\n",
       "        0.0295, -0.0374, -0.0339, -0.0563, -0.0354, -0.0005,  0.0027,\n",
       "       -0.024 , -0.0533,  0.0511,  0.0809, -0.0045, -0.0284,  0.0167,\n",
       "        0.056 , -0.0101, -0.0091,  0.0739,  0.0074,  0.0707, -0.0873,\n",
       "       -0.0338,  0.075 ,  0.05  , -0.0404,  0.026 ,  0.0617,  0.0071,\n",
       "       -0.01  ,  0.0452, -0.1058, -0.0298,  0.0631,  0.0463, -0.1158,\n",
       "       -0.1217,  0.0917,  0.0172,  0.0171, -0.0064,  0.1632,  0.0642,\n",
       "        0.0418, -0.0055, -0.0374,  0.004 ,  0.0315,  0.0014,  0.0588,\n",
       "        0.0506,  0.0019, -0.037 ,  0.0823, -0.0206, -0.0767, -0.0211,\n",
       "        0.0344, -0.0358,  0.0643, -0.0314, -0.0148,  0.023 ,  0.069 ,\n",
       "       -0.0091,  0.0156,  0.0373, -0.0381,  0.0122, -0.1174, -0.0934,\n",
       "        0.0038, -0.0573,  0.0552, -0.0199, -0.0313, -0.0342, -0.0894,\n",
       "        0.065 , -0.0053,  0.0096, -0.0571,  0.0231,  0.0461,  0.0445,\n",
       "       -0.041 ,  0.0344, -0.0186,  0.0442, -0.0503,  0.018 ,  0.0925,\n",
       "       -0.0807, -0.0429, -0.0522,  0.02  , -0.0374, -0.0068,  0.0542,\n",
       "       -0.0277, -0.0874, -0.0169,  0.058 ,  0.0075,  0.0299, -0.0249,\n",
       "        0.1195, -0.0254,  0.0416, -0.0983, -0.0656,  0.0419,  0.024 ,\n",
       "       -0.0476,  0.0721, -0.0743, -0.06  ,  0.0434,  0.0977, -0.0128,\n",
       "        0.0038, -0.0203, -0.0488,  0.0142, -0.0982,  0.0138,  0.0135,\n",
       "        0.073 ,  0.0822, -0.0434, -0.0024, -0.0869, -0.0512, -0.0378,\n",
       "       -0.0327, -0.0312,  0.0039, -0.0395, -0.0155, -0.0032,  0.0189,\n",
       "       -0.0907,  0.0206,  0.052 ,  0.0247,  0.0491, -0.0683, -0.0185,\n",
       "        0.0565, -0.0731,  0.0577, -0.0633,  0.1095, -0.0025,  0.0055,\n",
       "       -0.0023, -0.0013, -0.025 ,  0.0219, -0.0497, -0.0267, -0.0263,\n",
       "       -0.0162,  0.0505,  0.1053,  0.0935, -0.0118,  0.0701,  0.0085,\n",
       "       -0.045 ,  0.034 ,  0.0222,  0.0709, -0.0245,  0.0158,  0.0312,\n",
       "       -0.0028, -0.027 ,  0.0858,  0.0353, -0.0397, -0.0115, -0.0481,\n",
       "        0.1474, -0.1225, -0.0587, -0.0176,  0.0128, -0.0014,  0.0384,\n",
       "        0.0486,  0.0181, -0.0222,  0.0013,  0.0129, -0.0398, -0.051 ,\n",
       "        0.033 , -0.0239, -0.0114, -0.038 ,  0.0513,  0.0479,  0.0399,\n",
       "        0.0149,  0.0261, -0.0701,  0.076 ,  0.0181,  0.0856, -0.0064,\n",
       "        0.0255,  0.0716, -0.0142,  0.0385,  0.0651, -0.0208, -0.0032,\n",
       "       -0.0224, -0.0486, -0.0413,  0.1549,  0.0043,  0.0405,  0.0472,\n",
       "       -0.0083, -0.0248, -0.0072, -0.0556,  0.0347,  0.0967,  0.0574,\n",
       "       -0.0449, -0.063 ,  0.0151, -0.0681,  0.0421, -0.0078,  0.0237,\n",
       "       -0.0594, -0.0552,  0.0204,  0.0608,  0.0393, -0.0869,  0.069 ,\n",
       "        0.0275, -0.0283, -0.0247,  0.002 , -0.0154, -0.0258, -0.0499,\n",
       "        0.1221,  0.0076,  0.0569, -0.0605,  0.1   ,  0.0122],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2[\"/c/en/anthropocentric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/c/af/1_konings': 0,\n",
       " '/c/af/2_konings': 1,\n",
       " '/c/af/a.s': 2,\n",
       " '/c/af/a_foei_tog': 3,\n",
       " '/c/af/a_ja_a': 4,\n",
       " '/c/af/a_nee_a': 5,\n",
       " '/c/af/aag': 6,\n",
       " '/c/af/aai': 7,\n",
       " '/c/af/aak': 8,\n",
       " '/c/af/aaklig': 9,\n",
       " '/c/af/aakligheid': 10,\n",
       " '/c/af/aal': 11,\n",
       " '/c/af/aalmoes': 12,\n",
       " '/c/af/aalmoesenier': 13,\n",
       " '/c/af/aalmoeseniershuis': 14,\n",
       " '/c/af/aalmoesgewer': 15,\n",
       " '/c/af/aaltjie': 16,\n",
       " '/c/af/aalwee': 17,\n",
       " '/c/af/aalwurm': 18,\n",
       " '/c/af/aalwyn': 19,\n",
       " '/c/af/aambeeld': 20,\n",
       " '/c/af/aambeeldvoël': 21,\n",
       " '/c/af/aambei': 22,\n",
       " '/c/af/aamborstig': 23,\n",
       " '/c/af/aamborstigheid': 24,\n",
       " '/c/af/aan': 25,\n",
       " '/c/af/aanbehoort': 26,\n",
       " '/c/af/aanbel': 27,\n",
       " '/c/af/aanbestee': 28,\n",
       " '/c/af/aanbetref': 29,\n",
       " '/c/af/aanbetrou': 30,\n",
       " '/c/af/aanbeveel': 31,\n",
       " '/c/af/aanbeveelbaar': 32,\n",
       " '/c/af/aanbevelenswaardig': 33,\n",
       " '/c/af/aanbeveling': 34,\n",
       " '/c/af/aanbid': 35,\n",
       " '/c/af/aanbidbaar': 36,\n",
       " '/c/af/aanbidbaarheid': 37,\n",
       " '/c/af/aanbiddelik': 38,\n",
       " '/c/af/aanbiddelikheid': 39,\n",
       " '/c/af/aanbied': 40,\n",
       " '/c/af/aanbieder': 41,\n",
       " '/c/af/aanbieding': 42,\n",
       " '/c/af/aanbind': 43,\n",
       " '/c/af/aanblik': 44,\n",
       " '/c/af/aanbly': 45,\n",
       " '/c/af/aanbod': 46,\n",
       " '/c/af/aanboor': 47,\n",
       " '/c/af/aanbots': 48,\n",
       " '/c/af/aanbou': 49,\n",
       " '/c/af/aanbreek': 50,\n",
       " '/c/af/aanbring': 51,\n",
       " '/c/af/aand': 52,\n",
       " '/c/af/aandag': 53,\n",
       " '/c/af/aandag_gee_aan': 54,\n",
       " '/c/af/aandagtig': 55,\n",
       " '/c/af/aandagtiglik': 56,\n",
       " '/c/af/aandeel': 57,\n",
       " '/c/af/aandeelhebber': 58,\n",
       " '/c/af/aandeelhouer': 59,\n",
       " '/c/af/aandete': 60,\n",
       " '/c/af/aandgrou': 61,\n",
       " '/c/af/aandoen': 62,\n",
       " '/c/af/aandoening': 63,\n",
       " '/c/af/aandra': 64,\n",
       " '/c/af/aandraag': 65,\n",
       " '/c/af/aandrang': 66,\n",
       " '/c/af/aandrif': 67,\n",
       " '/c/af/aandring': 68,\n",
       " '/c/af/aandruk': 69,\n",
       " '/c/af/aandryf': 70,\n",
       " '/c/af/aandrywe': 71,\n",
       " '/c/af/aandskemering': 72,\n",
       " '/c/af/aandui': 73,\n",
       " '/c/af/aanduiding': 74,\n",
       " '/c/af/aandurf': 75,\n",
       " '/c/af/aaneen': 76,\n",
       " '/c/af/aaneenbind': 77,\n",
       " '/c/af/aaneenskakeling': 78,\n",
       " '/c/af/aaneenvoeg': 79,\n",
       " '/c/af/aangee': 80,\n",
       " '/c/af/aangenaam': 81,\n",
       " '/c/af/aangenome': 82,\n",
       " '/c/af/aangesien': 83,\n",
       " '/c/af/aangeskote': 84,\n",
       " '/c/af/aangewing': 85,\n",
       " '/c/af/aangry': 86,\n",
       " '/c/af/aanhanger': 87,\n",
       " '/c/af/aanhanklik': 88,\n",
       " '/c/af/aanhou': 89,\n",
       " '/c/af/aanhoudelik': 90,\n",
       " '/c/af/aanhoudend': 91,\n",
       " '/c/af/aanhouding': 92,\n",
       " '/c/af/aanhê': 93,\n",
       " '/c/af/aankla': 94,\n",
       " '/c/af/aanklaag': 95,\n",
       " '/c/af/aanklae': 96,\n",
       " '/c/af/aanklaer': 97,\n",
       " '/c/af/aankleef': 98,\n",
       " '/c/af/aanklewer': 99,\n",
       " '/c/af/aanklewing': 100,\n",
       " '/c/af/aankom': 101,\n",
       " '/c/af/aankoms': 102,\n",
       " '/c/af/aankoop': 103,\n",
       " '/c/af/aankweek': 104,\n",
       " '/c/af/aankyk': 105,\n",
       " '/c/af/aanland': 106,\n",
       " '/c/af/aanlegplek': 107,\n",
       " '/c/af/aanlok': 108,\n",
       " '/c/af/aanloklik': 109,\n",
       " '/c/af/aanloksel': 110,\n",
       " '/c/af/aanlêplaas': 111,\n",
       " '/c/af/aanlêplek': 112,\n",
       " '/c/af/aanmaak': 113,\n",
       " '/c/af/aanmaning': 114,\n",
       " '/c/af/aanmerklik': 115,\n",
       " '/c/af/aanminlik': 116,\n",
       " '/c/af/aanmoedig': 117,\n",
       " '/c/af/aanneembaar': 118,\n",
       " '/c/af/aanneemlik': 119,\n",
       " '/c/af/aanpak': 120,\n",
       " '/c/af/aanpas': 121,\n",
       " '/c/af/aanpasser': 122,\n",
       " '/c/af/aanpassing': 123,\n",
       " '/c/af/aanplak': 124,\n",
       " '/c/af/aanplakbiljet': 125,\n",
       " '/c/af/aanplakbord': 126,\n",
       " '/c/af/aanprys': 127,\n",
       " '/c/af/aanprysing': 128,\n",
       " '/c/af/aanraai': 129,\n",
       " '/c/af/aanrading': 130,\n",
       " '/c/af/aanranding': 131,\n",
       " '/c/af/aanroep': 132,\n",
       " '/c/af/aans': 133,\n",
       " '/c/af/aansien': 134,\n",
       " '/c/af/aansies': 135,\n",
       " '/c/af/aansig': 136,\n",
       " '/c/af/aansit': 137,\n",
       " '/c/af/aanskaf': 138,\n",
       " '/c/af/aanskaffing': 139,\n",
       " '/c/af/aanskakel': 140,\n",
       " '/c/af/aanskerp': 141,\n",
       " '/c/af/aanslag': 142,\n",
       " '/c/af/aansluit': 143,\n",
       " '/c/af/aansluiting': 144,\n",
       " '/c/af/aansoek_doen': 145,\n",
       " '/c/af/aanspreeklik': 146,\n",
       " '/c/af/aanstaande': 147,\n",
       " '/c/af/aansteek': 148,\n",
       " '/c/af/aansterf': 149,\n",
       " '/c/af/aanstoot': 150,\n",
       " '/c/af/aansyn': 151,\n",
       " '/c/af/aantal': 152,\n",
       " '/c/af/aanteken': 153,\n",
       " '/c/af/aantekening': 154,\n",
       " '/c/af/aantoon': 155,\n",
       " '/c/af/aantrek': 156,\n",
       " '/c/af/aantrekking': 157,\n",
       " '/c/af/aantreklik': 158,\n",
       " '/c/af/aanvaar': 159,\n",
       " '/c/af/aanvaarbaar': 160,\n",
       " '/c/af/aanvaarder': 161,\n",
       " '/c/af/aanval': 162,\n",
       " '/c/af/aanvaller': 163,\n",
       " '/c/af/aanvallig': 164,\n",
       " '/c/af/aanvang': 165,\n",
       " '/c/af/aanvul': 166,\n",
       " '/c/af/aap': 167,\n",
       " '/c/af/aar': 168,\n",
       " '/c/af/aarbei': 169,\n",
       " '/c/af/aard': 170,\n",
       " '/c/af/aardbewing': 171,\n",
       " '/c/af/aarde': 172,\n",
       " '/c/af/aardgees': 173,\n",
       " '/c/af/aardhommel': 174,\n",
       " '/c/af/aardig': 175,\n",
       " '/c/af/aardmannetjie': 176,\n",
       " '/c/af/aardrykskundig': 177,\n",
       " '/c/af/aardskudding': 178,\n",
       " '/c/af/aardtrilling': 179,\n",
       " '/c/af/aardvark': 180,\n",
       " '/c/af/aardwolf': 181,\n",
       " '/c/af/aars': 182,\n",
       " '/c/af/aartappel': 183,\n",
       " '/c/af/aartsbiskop': 184,\n",
       " '/c/af/aartsengel': 185,\n",
       " '/c/af/aartsherog': 186,\n",
       " '/c/af/aarverkalking': 187,\n",
       " '/c/af/aas': 188,\n",
       " '/c/af/aasdier': 189,\n",
       " '/c/af/aasvoël': 190,\n",
       " '/c/af/abakus': 191,\n",
       " '/c/af/abattoir': 192,\n",
       " '/c/af/abc': 193,\n",
       " '/c/af/abdikasie': 194,\n",
       " '/c/af/abdikeer': 195,\n",
       " '/c/af/abdomen': 196,\n",
       " '/c/af/abdy': 197,\n",
       " '/c/af/aberrasie': 198,\n",
       " '/c/af/ablatief': 199,\n",
       " '/c/af/abnormaal': 200,\n",
       " '/c/af/abonnee': 201,\n",
       " '/c/af/abonneer': 202,\n",
       " '/c/af/aborsie': 203,\n",
       " '/c/af/abortief': 204,\n",
       " '/c/af/abortus': 205,\n",
       " '/c/af/abrogasie': 206,\n",
       " '/c/af/abrup': 207,\n",
       " '/c/af/absensie': 208,\n",
       " '/c/af/absent': 209,\n",
       " '/c/af/absint': 210,\n",
       " '/c/af/absolusie': 211,\n",
       " '/c/af/absoluut': 212,\n",
       " '/c/af/absorbeer': 213,\n",
       " '/c/af/abstrak': 214,\n",
       " '/c/af/abstraksie': 215,\n",
       " '/c/af/abstraktheid': 216,\n",
       " '/c/af/absurd': 217,\n",
       " '/c/af/absurditeit': 218,\n",
       " '/c/af/abuis': 219,\n",
       " '/c/af/abusieflik': 220,\n",
       " '/c/af/achternadraai': 221,\n",
       " '/c/af/adamsappel': 222,\n",
       " '/c/af/adapteer': 223,\n",
       " '/c/af/addis_abeba': 224,\n",
       " '/c/af/adelaar': 225,\n",
       " '/c/af/adem': 226,\n",
       " '/c/af/adhesie': 227,\n",
       " '/c/af/adjudant': 228,\n",
       " '/c/af/administrasie': 229,\n",
       " '/c/af/administrateur': 230,\n",
       " '/c/af/administratief': 231,\n",
       " '/c/af/adoreer': 232,\n",
       " '/c/af/adrastea': 233,\n",
       " '/c/af/adrenalien': 234,\n",
       " '/c/af/adrenaline': 235,\n",
       " '/c/af/adres': 236,\n",
       " '/c/af/adresboek': 237,\n",
       " '/c/af/adresseer': 238,\n",
       " '/c/af/adverbiaal': 239,\n",
       " '/c/af/adverbium': 240,\n",
       " '/c/af/advies': 241,\n",
       " '/c/af/adviseer': 242,\n",
       " '/c/af/advokaat': 243,\n",
       " '/c/af/afdeling': 244,\n",
       " '/c/af/afding': 245,\n",
       " '/c/af/affiks': 246,\n",
       " '/c/af/affêre': 247,\n",
       " '/c/af/affêring': 248,\n",
       " '/c/af/afgaan': 249,\n",
       " '/c/af/afgebete': 250,\n",
       " '/c/af/afgebetenheid': 251,\n",
       " '/c/af/afgelope': 252,\n",
       " '/c/af/afgetrokkenheid': 253,\n",
       " '/c/af/afghanistan': 254,\n",
       " '/c/af/afgrond': 255,\n",
       " '/c/af/afgryse': 256,\n",
       " '/c/af/afgryslik': 257,\n",
       " '/c/af/afhaal': 258,\n",
       " '/c/af/afkappingsteken': 259,\n",
       " '/c/af/afkondig': 260,\n",
       " '/c/af/aflewer': 261,\n",
       " '/c/af/afmeting': 262,\n",
       " '/c/af/afoes': 263,\n",
       " '/c/af/afrika': 264,\n",
       " '/c/af/afrika_unie': 265,\n",
       " '/c/af/afrikaans': 266,\n",
       " '/c/af/afrikaanssprekende': 267,\n",
       " '/c/af/afrikaner': 268,\n",
       " '/c/af/afruim': 269,\n",
       " '/c/af/afruk': 270,\n",
       " '/c/af/afry': 271,\n",
       " '/c/af/afsaksel': 272,\n",
       " '/c/af/afsegging': 273,\n",
       " '/c/af/afsien': 274,\n",
       " '/c/af/afsien_van': 275,\n",
       " '/c/af/afsigtelik': 276,\n",
       " '/c/af/afsit': 277,\n",
       " '/c/af/afsitting': 278,\n",
       " '/c/af/afskaf': 279,\n",
       " '/c/af/afskaffer': 280,\n",
       " '/c/af/afskaffing': 281,\n",
       " '/c/af/afskei': 282,\n",
       " '/c/af/afskeid_neem': 283,\n",
       " '/c/af/afskeur': 284,\n",
       " '/c/af/afskilder': 285,\n",
       " '/c/af/afskrik': 286,\n",
       " '/c/af/afskuwelik': 287,\n",
       " '/c/af/afslaan': 288,\n",
       " '/c/af/afslag': 289,\n",
       " '/c/af/afsluit': 290,\n",
       " '/c/af/afsny': 291,\n",
       " '/c/af/afsonder': 292,\n",
       " '/c/af/afsonderlik': 293,\n",
       " '/c/af/afsper': 294,\n",
       " '/c/af/afspoel': 295,\n",
       " '/c/af/afspraak': 296,\n",
       " '/c/af/afstammeling': 297,\n",
       " '/c/af/afstand': 298,\n",
       " '/c/af/afstap': 299,\n",
       " '/c/af/afsteek': 300,\n",
       " '/c/af/afstempel': 301,\n",
       " '/c/af/afstomp': 302,\n",
       " '/c/af/afsydig': 303,\n",
       " '/c/af/afsê': 304,\n",
       " '/c/af/aftandig': 305,\n",
       " '/c/af/aftands': 306,\n",
       " '/c/af/aftap': 307,\n",
       " '/c/af/afteken': 308,\n",
       " '/c/af/aftree': 309,\n",
       " '/c/af/aftrek': 310,\n",
       " '/c/af/aftrekking': 311,\n",
       " '/c/af/afvaar': 312,\n",
       " '/c/af/afval': 313,\n",
       " '/c/af/afvallige': 314,\n",
       " '/c/af/afvee': 315,\n",
       " '/c/af/afveeg': 316,\n",
       " '/c/af/afwater': 317,\n",
       " '/c/af/afweer': 318,\n",
       " '/c/af/afwerp': 319,\n",
       " '/c/af/afwesig': 320,\n",
       " '/c/af/afwesig_wees': 321,\n",
       " '/c/af/afwesigheid': 322,\n",
       " '/c/af/afwikkel': 323,\n",
       " '/c/af/afwimpel': 324,\n",
       " '/c/af/afwis': 325,\n",
       " '/c/af/afwyk': 326,\n",
       " '/c/af/afwyking': 327,\n",
       " '/c/af/afwys': 328,\n",
       " '/c/af/ag': 329,\n",
       " '/c/af/ag_slaan_op': 330,\n",
       " '/c/af/agaat': 331,\n",
       " '/c/af/ageer': 332,\n",
       " '/c/af/agenda': 333,\n",
       " '/c/af/agent': 334,\n",
       " '/c/af/agglomeraat': 335,\n",
       " '/c/af/aggressief': 336,\n",
       " '/c/af/aghoek': 337,\n",
       " '/c/af/agitasie': 338,\n",
       " '/c/af/agitator': 339,\n",
       " '/c/af/agiteer': 340,\n",
       " '/c/af/agiteerder': 341,\n",
       " '/c/af/agorafobie': 342,\n",
       " '/c/af/agrariër': 343,\n",
       " '/c/af/agt': 344,\n",
       " '/c/af/agt_en_dertig': 345,\n",
       " '/c/af/agt_en_negentig': 346,\n",
       " '/c/af/agt_en_tagtig': 347,\n",
       " '/c/af/agt_en_twintig': 348,\n",
       " '/c/af/agt_en_veertig': 349,\n",
       " '/c/af/agteloos': 350,\n",
       " '/c/af/agtelosig': 351,\n",
       " '/c/af/agter': 352,\n",
       " '/c/af/agter_wees': 353,\n",
       " '/c/af/agteraan': 354,\n",
       " '/c/af/agtereen': 355,\n",
       " '/c/af/agtereenvolgens': 356,\n",
       " '/c/af/agterent': 357,\n",
       " '/c/af/agterin': 358,\n",
       " '/c/af/agterkleindogter': 359,\n",
       " '/c/af/agterloop': 360,\n",
       " '/c/af/agterlosig': 361,\n",
       " '/c/af/agterlyf': 362,\n",
       " '/c/af/agternadraai': 363,\n",
       " '/c/af/agterneef': 364,\n",
       " '/c/af/agternig': 365,\n",
       " '/c/af/agterniggie': 366,\n",
       " '/c/af/agterste': 367,\n",
       " '/c/af/agtervoegsel': 368,\n",
       " '/c/af/agthonderd': 369,\n",
       " '/c/af/agtien': 370,\n",
       " '/c/af/agtiende': 371,\n",
       " '/c/af/agting': 372,\n",
       " '/c/af/agtste': 373,\n",
       " '/c/af/agttien': 374,\n",
       " '/c/af/aikôna': 375,\n",
       " '/c/af/air': 376,\n",
       " '/c/af/aix_en_provence': 377,\n",
       " '/c/af/akant': 378,\n",
       " '/c/af/akasia': 379,\n",
       " '/c/af/aken': 380,\n",
       " '/c/af/akkedis': 381,\n",
       " '/c/af/akkeldis': 382,\n",
       " '/c/af/akker': 383,\n",
       " '/c/af/akkerboom': 384,\n",
       " '/c/af/akkerdis': 385,\n",
       " '/c/af/akkermonie': 386,\n",
       " '/c/af/akklimatisasie': 387,\n",
       " '/c/af/akklimatisering': 388,\n",
       " '/c/af/akkompanjis': 389,\n",
       " '/c/af/akkoord': 390,\n",
       " '/c/af/akkumulator': 391,\n",
       " '/c/af/akkuraat': 392,\n",
       " '/c/af/akkuraatheid': 393,\n",
       " '/c/af/akne': 394,\n",
       " '/c/af/akoliet': 395,\n",
       " '/c/af/akrofobie': 396,\n",
       " '/c/af/akropolis': 397,\n",
       " '/c/af/akselerasie': 398,\n",
       " '/c/af/aksent': 399,\n",
       " '/c/af/aksenteken': 400,\n",
       " '/c/af/aksentloos': 401,\n",
       " '/c/af/aksentueer': 402,\n",
       " '/c/af/akseptabel': 403,\n",
       " '/c/af/akseptant': 404,\n",
       " '/c/af/aksie': 405,\n",
       " '/c/af/aksioma': 406,\n",
       " '/c/af/aksionaris': 407,\n",
       " '/c/af/aksioom': 408,\n",
       " '/c/af/aksyns': 409,\n",
       " '/c/af/aksynskantoor': 410,\n",
       " '/c/af/akteur': 411,\n",
       " '/c/af/aktief': 412,\n",
       " '/c/af/aktinium': 413,\n",
       " '/c/af/aktiveer': 414,\n",
       " '/c/af/akwarium': 415,\n",
       " '/c/af/al': 416,\n",
       " '/c/af/alarm': 417,\n",
       " '/c/af/alarmeer': 418,\n",
       " '/c/af/albanees': 419,\n",
       " '/c/af/albanies': 420,\n",
       " '/c/af/albanië': 421,\n",
       " '/c/af/albatros': 422,\n",
       " '/c/af/albei': 423,\n",
       " '/c/af/alchemie': 424,\n",
       " '/c/af/aldaar': 425,\n",
       " '/c/af/aldehide': 426,\n",
       " '/c/af/aldeur': 427,\n",
       " '/c/af/alfabet': 428,\n",
       " '/c/af/alg': 429,\n",
       " '/c/af/alge': 430,\n",
       " '/c/af/algebra': 431,\n",
       " '/c/af/algebraïes': 432,\n",
       " '/c/af/algerië': 433,\n",
       " '/c/af/alhaas': 434,\n",
       " '/c/af/alkali': 435,\n",
       " '/c/af/alkalies': 436,\n",
       " '/c/af/alkalimetaal': 437,\n",
       " '/c/af/alkaloïde': 438,\n",
       " '/c/af/alkaloïed': 439,\n",
       " '/c/af/alkohol': 440,\n",
       " '/c/af/alkoholvry': 441,\n",
       " '/c/af/alledaags': 442,\n",
       " '/c/af/alleen': 443,\n",
       " '/c/af/alleenheid': 444,\n",
       " '/c/af/allegorie': 445,\n",
       " '/c/af/allengs': 446,\n",
       " '/c/af/allengskens': 447,\n",
       " '/c/af/allenig': 448,\n",
       " '/c/af/allerhande': 449,\n",
       " '/c/af/allerlei': 450,\n",
       " '/c/af/allerweë': 451,\n",
       " '/c/af/allesbehalwe': 452,\n",
       " '/c/af/alliasie': 453,\n",
       " '/c/af/allig': 454,\n",
       " '/c/af/alligator': 455,\n",
       " '/c/af/alliterasie': 456,\n",
       " '/c/af/allooi': 457,\n",
       " '/c/af/almal': 458,\n",
       " '/c/af/almanak': 459,\n",
       " '/c/af/almeteens': 460,\n",
       " '/c/af/alom': 461,\n",
       " '/c/af/alpakka': 462,\n",
       " '/c/af/alpe': 463,\n",
       " '/c/af/alperoos': 464,\n",
       " '/c/af/alpinis': 465,\n",
       " '/c/af/alras': 466,\n",
       " '/c/af/alreeds': 467,\n",
       " '/c/af/als': 468,\n",
       " '/c/af/alsem': 469,\n",
       " '/c/af/also': 470,\n",
       " '/c/af/altaar': 471,\n",
       " '/c/af/altaardienaar': 472,\n",
       " '/c/af/altemit': 473,\n",
       " '/c/af/altemits': 474,\n",
       " '/c/af/altemitters': 475,\n",
       " '/c/af/altoos': 476,\n",
       " '/c/af/altwee': 477,\n",
       " '/c/af/altyd': 478,\n",
       " '/c/af/altyddurend': 479,\n",
       " '/c/af/aluminium': 480,\n",
       " '/c/af/alweer': 481,\n",
       " '/c/af/amandel': 482,\n",
       " '/c/af/amarant': 483,\n",
       " '/c/af/ambag': 484,\n",
       " '/c/af/amber': 485,\n",
       " '/c/af/ambieer': 486,\n",
       " '/c/af/ambigeer': 487,\n",
       " '/c/af/ambroos': 488,\n",
       " '/c/af/ambrosyn': 489,\n",
       " '/c/af/amebe': 490,\n",
       " '/c/af/amharies': 491,\n",
       " '/c/af/ammoniak': 492,\n",
       " '/c/af/amp': 493,\n",
       " '/c/af/amper': 494,\n",
       " '/c/af/ampertjies': 495,\n",
       " '/c/af/ampgenoot': 496,\n",
       " '/c/af/ampsbroer': 497,\n",
       " '/c/af/amptelik': 498,\n",
       " '/c/af/amputasie': 499,\n",
       " '/c/af/amputeer': 500,\n",
       " '/c/af/ampère': 501,\n",
       " '/c/af/amsterdam': 502,\n",
       " '/c/af/amusement': 503,\n",
       " '/c/af/anagram': 504,\n",
       " '/c/af/analfabeet': 505,\n",
       " '/c/af/analise': 506,\n",
       " '/c/af/analogie': 507,\n",
       " '/c/af/ananas': 508,\n",
       " '/c/af/anargis': 509,\n",
       " '/c/af/anargisme': 510,\n",
       " '/c/af/anatomie': 511,\n",
       " '/c/af/anders': 512,\n",
       " '/c/af/andorra': 513,\n",
       " '/c/af/andries': 514,\n",
       " '/c/af/anemie': 515,\n",
       " '/c/af/angel': 516,\n",
       " '/c/af/angina': 517,\n",
       " '/c/af/angola': 518,\n",
       " '/c/af/angs': 519,\n",
       " '/c/af/angstig': 520,\n",
       " '/c/af/angswekkend': 521,\n",
       " '/c/af/animo': 522,\n",
       " '/c/af/anker': 523,\n",
       " '/c/af/annulleer': 524,\n",
       " '/c/af/annullering': 525,\n",
       " '/c/af/antidoot': 526,\n",
       " '/c/af/antiek': 527,\n",
       " '/c/af/antiloop': 528,\n",
       " '/c/af/antimonium': 529,\n",
       " '/c/af/antimoon': 530,\n",
       " '/c/af/antisemitisme': 531,\n",
       " '/c/af/antoniem': 532,\n",
       " '/c/af/antropologie': 533,\n",
       " '/c/af/antwoord': 534,\n",
       " '/c/af/anus': 535,\n",
       " '/c/af/anys': 536,\n",
       " '/c/af/apart': 537,\n",
       " '/c/af/apartheid': 538,\n",
       " '/c/af/apatie': 539,\n",
       " '/c/af/apebroodboom': 540,\n",
       " '/c/af/apopleksie': 541,\n",
       " '/c/af/apostaat': 542,\n",
       " '/c/af/apostel': 543,\n",
       " '/c/af/apostelskap': 544,\n",
       " '/c/af/apostolaat': 545,\n",
       " '/c/af/apostroof': 546,\n",
       " '/c/af/apparaat': 547,\n",
       " '/c/af/appartement': 548,\n",
       " '/c/af/appel': 549,\n",
       " '/c/af/appelboom': 550,\n",
       " '/c/af/appeldrank': 551,\n",
       " '/c/af/appelkoos': 552,\n",
       " '/c/af/appelwyn': 553,\n",
       " '/c/af/applikant': 554,\n",
       " '/c/af/appèl': 555,\n",
       " '/c/af/april': 556,\n",
       " '/c/af/apteek': 557,\n",
       " '/c/af/apteker': 558,\n",
       " '/c/af/arabies': 559,\n",
       " '/c/af/aragnied': 560,\n",
       " '/c/af/arbei': 561,\n",
       " '/c/af/arbeid': 562,\n",
       " '/c/af/arbeider': 563,\n",
       " '/c/af/area': 564,\n",
       " '/c/af/arena': 565,\n",
       " '/c/af/arend': 566,\n",
       " '/c/af/argaïsme': 567,\n",
       " '/c/af/argentinië': 568,\n",
       " '/c/af/argeologie': 569,\n",
       " '/c/af/argiefbewaarder': 570,\n",
       " '/c/af/argipel': 571,\n",
       " '/c/af/argitek': 572,\n",
       " '/c/af/argitektuur': 573,\n",
       " '/c/af/argivaris': 574,\n",
       " '/c/af/argon': 575,\n",
       " '/c/af/argument': 576,\n",
       " '/c/af/aria': 577,\n",
       " '/c/af/ariel': 578,\n",
       " '/c/af/aristokraat': 579,\n",
       " '/c/af/arm': 580,\n",
       " '/c/af/armenies': 581,\n",
       " '/c/af/armenië': 582,\n",
       " '/c/af/armhorlosie': 583,\n",
       " '/c/af/arnika': 584,\n",
       " '/c/af/arrestasie': 585,\n",
       " '/c/af/arriveer': 586,\n",
       " '/c/af/arseen': 587,\n",
       " '/c/af/arsenik': 588,\n",
       " '/c/af/arsenikum': 589,\n",
       " '/c/af/arteriosklerose': 590,\n",
       " '/c/af/artis': 591,\n",
       " '/c/af/artisjok': 592,\n",
       " '/c/af/artritis': 593,\n",
       " '/c/af/arts': 594,\n",
       " '/c/af/artseny': 595,\n",
       " '/c/af/aruba': 596,\n",
       " '/c/af/as': 597,\n",
       " '/c/af/asbes': 598,\n",
       " '/c/af/asem': 599,\n",
       " '/c/af/asemhaal': 600,\n",
       " '/c/af/asfalt': 601,\n",
       " '/c/af/asiel': 602,\n",
       " '/c/af/asië': 603,\n",
       " '/c/af/asketisme': 604,\n",
       " '/c/af/asma': 605,\n",
       " '/c/af/asmaties': 606,\n",
       " '/c/af/asof': 607,\n",
       " '/c/af/aspek': 608,\n",
       " '/c/af/aspersie': 609,\n",
       " '/c/af/asseblief': 610,\n",
       " '/c/af/assisteer': 611,\n",
       " '/c/af/assuransie': 612,\n",
       " '/c/af/assureer': 613,\n",
       " '/c/af/astaat': 614,\n",
       " '/c/af/asteroïde': 615,\n",
       " '/c/af/asteroïed': 616,\n",
       " '/c/af/astrologie': 617,\n",
       " '/c/af/astronomie': 618,\n",
       " '/c/af/asyn': 619,\n",
       " '/c/af/asynsuur': 620,\n",
       " '/c/af/ateïsme': 621,\n",
       " '/c/af/athene': 622,\n",
       " '/c/af/atlantiese_oseaan': 623,\n",
       " '/c/af/atlas': 624,\n",
       " '/c/af/atol': 625,\n",
       " '/c/af/atoom': 626,\n",
       " '/c/af/atoomgetal': 627,\n",
       " '/c/af/attensie': 628,\n",
       " '/c/af/attent': 629,\n",
       " '/c/af/aude': 630,\n",
       " '/c/af/augustus': 631,\n",
       " '/c/af/australië': 632,\n",
       " '/c/af/avokado': 633,\n",
       " '/c/af/avokadopeer': 634,\n",
       " '/c/af/awend': 635,\n",
       " '/c/af/azerbaidjan': 636,\n",
       " '/c/af/azeri': 637,\n",
       " '/c/af/aërodinamika': 638,\n",
       " '/c/af/baadjie': 639,\n",
       " '/c/af/baaierd': 640,\n",
       " '/c/af/baaihokkie': 641,\n",
       " '/c/af/baaiklere': 642,\n",
       " '/c/af/baaikostuum': 643,\n",
       " '/c/af/baan': 644,\n",
       " '/c/af/baantjie': 645,\n",
       " '/c/af/baar': 646,\n",
       " '/c/af/baard': 647,\n",
       " '/c/af/baardaasvoël': 648,\n",
       " '/c/af/baarmoeder': 649,\n",
       " '/c/af/baas': 650,\n",
       " '/c/af/baat': 651,\n",
       " '/c/af/baba': 652,\n",
       " '/c/af/babetjie': 653,\n",
       " '/c/af/bad': 654,\n",
       " '/c/af/baden_württemberg': 655,\n",
       " '/c/af/badhokkie': 656,\n",
       " '/c/af/badkamer': 657,\n",
       " '/c/af/badklere': 658,\n",
       " '/c/af/badkostuum': 659,\n",
       " '/c/af/badkuip': 660,\n",
       " '/c/af/badpak': 661,\n",
       " '/c/af/bagasie': 662,\n",
       " '/c/af/bagatel': 663,\n",
       " '/c/af/baie': 664,\n",
       " '/c/af/baie_dankie': 665,\n",
       " '/c/af/bak': 666,\n",
       " '/c/af/bakatel': 667,\n",
       " '/c/af/bakker': 668,\n",
       " '/c/af/bakkie': 669,\n",
       " '/c/af/baksteen': 670,\n",
       " '/c/af/bakster': 671,\n",
       " '/c/af/bakterie': 672,\n",
       " '/c/af/bakteriologie': 673,\n",
       " '/c/af/bal': 674,\n",
       " '/c/af/balans': 675,\n",
       " '/c/af/balk': 676,\n",
       " '/c/af/ballerina': 677,\n",
       " '/c/af/balletdanseres': 678,\n",
       " '/c/af/balling': 679,\n",
       " '/c/af/ballingskap': 680,\n",
       " '/c/af/bamako': 681,\n",
       " '/c/af/banaal': 682,\n",
       " '/c/af/banana': 683,\n",
       " '/c/af/banjul': 684,\n",
       " '/c/af/bank': 685,\n",
       " '/c/af/banneling': 686,\n",
       " '/c/af/bannelingskap': 687,\n",
       " '/c/af/baobab': 688,\n",
       " '/c/af/barium': 689,\n",
       " '/c/af/barnsteen': 690,\n",
       " '/c/af/barometer': 691,\n",
       " '/c/af/basaar': 692,\n",
       " '/c/af/baseer': 693,\n",
       " '/c/af/basiliek': 694,\n",
       " '/c/af/basilika': 695,\n",
       " '/c/af/basis': 696,\n",
       " '/c/af/basketbal': 697,\n",
       " '/c/af/baskies': 698,\n",
       " '/c/af/battery': 699,\n",
       " '/c/af/bazaar': 700,\n",
       " '/c/af/beampte': 701,\n",
       " '/c/af/bed': 702,\n",
       " '/c/af/bedank': 703,\n",
       " '/c/af/beddeken': 704,\n",
       " '/c/af/beddekussing': 705,\n",
       " '/c/af/bedding': 706,\n",
       " '/c/af/bedehuis': 707,\n",
       " '/c/af/bedek': 708,\n",
       " '/c/af/bedel': 709,\n",
       " '/c/af/bedelaar': 710,\n",
       " '/c/af/bedelary': 711,\n",
       " '/c/af/bedelbroeder': 712,\n",
       " '/c/af/bedelmonnik': 713,\n",
       " '/c/af/bedelry': 714,\n",
       " '/c/af/bederf': 715,\n",
       " '/c/af/bederwe': 716,\n",
       " '/c/af/bedien': 717,\n",
       " '/c/af/bediende': 718,\n",
       " '/c/af/beding': 719,\n",
       " '/c/af/bedinging': 720,\n",
       " '/c/af/bedink': 721,\n",
       " '/c/af/bedissel': 722,\n",
       " '/c/af/bedkussing': 723,\n",
       " '/c/af/bedlaken': 724,\n",
       " '/c/af/bedoeling': 725,\n",
       " '/c/af/bedol': 726,\n",
       " '/c/af/bedot': 727,\n",
       " '/c/af/bedrag': 728,\n",
       " '/c/af/bedreig': 729,\n",
       " '/c/af/bedreiging': 730,\n",
       " '/c/af/bedrewe': 731,\n",
       " '/c/af/bedrewenheid': 732,\n",
       " '/c/af/bedrieg': 733,\n",
       " '/c/af/bedrië': 734,\n",
       " '/c/af/bedroefdheid': 735,\n",
       " '/c/af/bedryf': 736,\n",
       " '/c/af/bedryfsleier': 737,\n",
       " '/c/af/bedrywe': 738,\n",
       " '/c/af/bedrywig': 739,\n",
       " '/c/af/bedrywigheid': 740,\n",
       " '/c/af/bedug': 741,\n",
       " '/c/af/bedugtheid': 742,\n",
       " '/c/af/beduidenis': 743,\n",
       " '/c/af/bedwing': 744,\n",
       " '/c/af/beef': 745,\n",
       " '/c/af/beek': 746,\n",
       " '/c/af/beeld': 747,\n",
       " '/c/af/beelderig': 748,\n",
       " '/c/af/beeldig': 749,\n",
       " '/c/af/beeldradio': 750,\n",
       " '/c/af/beeldskoon': 751,\n",
       " '/c/af/beeltenis': 752,\n",
       " '/c/af/been': 753,\n",
       " '/c/af/beer': 754,\n",
       " '/c/af/beerklou': 755,\n",
       " '/c/af/beerwyfie': 756,\n",
       " '/c/af/bees': 757,\n",
       " '/c/af/beesvleis': 758,\n",
       " '/c/af/beetgryp': 759,\n",
       " '/c/af/beethê': 760,\n",
       " '/c/af/beetkry': 761,\n",
       " '/c/af/beetneem': 762,\n",
       " '/c/af/beetpak': 763,\n",
       " '/c/af/beetvat': 764,\n",
       " '/c/af/befaamd': 765,\n",
       " '/c/af/befaamdheid': 766,\n",
       " '/c/af/befok': 767,\n",
       " '/c/af/begaan': 768,\n",
       " '/c/af/begeef_hom': 769,\n",
       " '/c/af/begeer': 770,\n",
       " '/c/af/begeerte': 771,\n",
       " '/c/af/begeester': 772,\n",
       " '/c/af/begeestering': 773,\n",
       " '/c/af/begeleider': 774,\n",
       " '/c/af/begeleier': 775,\n",
       " '/c/af/begenadig': 776,\n",
       " '/c/af/begenadiging': 777,\n",
       " '/c/af/begerig': 778,\n",
       " '/c/af/begerigheid': 779,\n",
       " '/c/af/begewe_hom': 780,\n",
       " '/c/af/begiet': 781,\n",
       " '/c/af/begiftig': 782,\n",
       " '/c/af/begin': 783,\n",
       " '/c/af/beginsel': 784,\n",
       " '/c/af/beginselverklaring': 785,\n",
       " '/c/af/begogelsing': 786,\n",
       " '/c/af/begonia': 787,\n",
       " '/c/af/begoëlsing': 788,\n",
       " '/c/af/begraafplaas': 789,\n",
       " '/c/af/begraafplek': 790,\n",
       " '/c/af/begrafnis': 791,\n",
       " '/c/af/begrawe': 792,\n",
       " '/c/af/begrawing': 793,\n",
       " '/c/af/begrens': 794,\n",
       " '/c/af/begrip': 795,\n",
       " '/c/af/begroet': 796,\n",
       " '/c/af/begroot': 797,\n",
       " '/c/af/begryp': 798,\n",
       " '/c/af/begyn': 799,\n",
       " '/c/af/begyntjie': 800,\n",
       " '/c/af/behaaglik': 801,\n",
       " '/c/af/behaal': 802,\n",
       " '/c/af/behalwe': 803,\n",
       " '/c/af/behandel': 804,\n",
       " '/c/af/behang': 805,\n",
       " '/c/af/behangsel': 806,\n",
       " '/c/af/behangselpapier': 807,\n",
       " '/c/af/behartig': 808,\n",
       " '/c/af/behartigenswaardig': 809,\n",
       " '/c/af/beheer': 810,\n",
       " '/c/af/beheers': 811,\n",
       " '/c/af/beheerser': 812,\n",
       " '/c/af/beheersing': 813,\n",
       " '/c/af/behels': 814,\n",
       " '/c/af/behendig': 815,\n",
       " '/c/af/behendigheid': 816,\n",
       " '/c/af/behoed': 817,\n",
       " '/c/af/behoef': 818,\n",
       " '/c/af/behoeftig': 819,\n",
       " '/c/af/behoor': 820,\n",
       " '/c/af/behoorlik': 821,\n",
       " '/c/af/behoorlikheidshalwe': 822,\n",
       " '/c/af/behoort': 823,\n",
       " '/c/af/behou': 824,\n",
       " '/c/af/behoud': 825,\n",
       " '/c/af/behoudenis': 826,\n",
       " '/c/af/behoue': 827,\n",
       " '/c/af/beide': 828,\n",
       " '/c/af/beier': 829,\n",
       " '/c/af/beiere': 830,\n",
       " '/c/af/beige': 831,\n",
       " '/c/af/beitel': 832,\n",
       " '/c/af/bejaard': 833,\n",
       " '/c/af/bejammer': 834,\n",
       " '/c/af/bek': 835,\n",
       " '/c/af/bek_en_klouseer': 836,\n",
       " '/c/af/beken': 837,\n",
       " '/c/af/bekendheid': 838,\n",
       " '/c/af/bekendmaak': 839,\n",
       " '/c/af/bekendmaking': 840,\n",
       " '/c/af/bekendstel': 841,\n",
       " '/c/af/bekentenis': 842,\n",
       " '/c/af/beker': 843,\n",
       " '/c/af/bekken': 844,\n",
       " '/c/af/beklaag': 845,\n",
       " '/c/af/beklaaglik': 846,\n",
       " '/c/af/beklad': 847,\n",
       " '/c/af/beklae': 848,\n",
       " '/c/af/beklaenswaardig': 849,\n",
       " '/c/af/beklag_doen': 850,\n",
       " '/c/af/beklagenswaardig': 851,\n",
       " '/c/af/beklee': 852,\n",
       " '/c/af/bekleed': 853,\n",
       " '/c/af/beklemtoon': 854,\n",
       " '/c/af/beklim': 855,\n",
       " '/c/af/beklouter': 856,\n",
       " '/c/af/beknibbel': 857,\n",
       " '/c/af/beknor': 858,\n",
       " '/c/af/bekom': 859,\n",
       " '/c/af/bekommer_hom': 860,\n",
       " '/c/af/bekommering': 861,\n",
       " '/c/af/bekommernis': 862,\n",
       " '/c/af/bekoor': 863,\n",
       " '/c/af/bekoorlik': 864,\n",
       " '/c/af/bekoring': 865,\n",
       " '/c/af/bekort': 866,\n",
       " '/c/af/bekragtig': 867,\n",
       " '/c/af/bekreun_hom': 868,\n",
       " '/c/af/bekritiseer': 869,\n",
       " '/c/af/bekrompe': 870,\n",
       " '/c/af/bekwaald': 871,\n",
       " '/c/af/bekwaam': 872,\n",
       " '/c/af/bekwaamheid': 873,\n",
       " '/c/af/bel': 874,\n",
       " '/c/af/beland': 875,\n",
       " '/c/af/belang': 876,\n",
       " '/c/af/belangrik': 877,\n",
       " '/c/af/belangrykheid': 878,\n",
       " '/c/af/belangwekkend': 879,\n",
       " '/c/af/belas': 880,\n",
       " '/c/af/belaster': 881,\n",
       " '/c/af/belasting': 882,\n",
       " '/c/af/beledig': 883,\n",
       " '/c/af/belediging': 884,\n",
       " '/c/af/beleef': 885,\n",
       " '/c/af/beleefdheid': 886,\n",
       " '/c/af/beleen': 887,\n",
       " '/c/af/beleg': 888,\n",
       " '/c/af/beleid': 889,\n",
       " '/c/af/belemmer': 890,\n",
       " '/c/af/belewe': 891,\n",
       " '/c/af/beleë': 892,\n",
       " '/c/af/beleëring': 893,\n",
       " '/c/af/belgië': 894,\n",
       " '/c/af/belinda': 895,\n",
       " '/c/af/beloof': 896,\n",
       " '/c/af/belowe': 897,\n",
       " '/c/af/beluister': 898,\n",
       " '/c/af/belus': 899,\n",
       " '/c/af/bely': 900,\n",
       " '/c/af/belydenis': 901,\n",
       " '/c/af/belê': 902,\n",
       " '/c/af/bemagtig': 903,\n",
       " '/c/af/bemerk': 904,\n",
       " '/c/af/bemerkbaar': 905,\n",
       " '/c/af/bemin': 906,\n",
       " '/c/af/beminnaar': 907,\n",
       " '/c/af/bemoedig': 908,\n",
       " '/c/af/benaam': 909,\n",
       " '/c/af/benaming': 910,\n",
       " '/c/af/benede': 911,\n",
       " '/c/af/benedeverdieping': 912,\n",
       " '/c/af/benedy': 913,\n",
       " '/c/af/beneem': 914,\n",
       " '/c/af/benepe': 915,\n",
       " '/c/af/benewel': 916,\n",
       " '/c/af/beneweld': 917,\n",
       " '/c/af/benin': 918,\n",
       " '/c/af/benodig': 919,\n",
       " '/c/af/benoem': 920,\n",
       " '/c/af/benou': 921,\n",
       " '/c/af/benoud': 922,\n",
       " '/c/af/benoudheid': 923,\n",
       " '/c/af/benouend': 924,\n",
       " '/c/af/bensien': 925,\n",
       " '/c/af/bensine': 926,\n",
       " '/c/af/benul': 927,\n",
       " '/c/af/benut': 928,\n",
       " '/c/af/benuttig': 929,\n",
       " '/c/af/beoordeel': 930,\n",
       " '/c/af/bepaal': 931,\n",
       " '/c/af/bepaling': 932,\n",
       " '/c/af/beperk': 933,\n",
       " '/c/af/beploe': 934,\n",
       " '/c/af/beploege': 935,\n",
       " '/c/af/beploë': 936,\n",
       " '/c/af/bepraat': 937,\n",
       " '/c/af/beproef': 938,\n",
       " '/c/af/beproewe': 939,\n",
       " '/c/af/beproewing': 940,\n",
       " '/c/af/beraming': 941,\n",
       " '/c/af/beredder': 942,\n",
       " '/c/af/berei': 943,\n",
       " '/c/af/bereid': 944,\n",
       " '/c/af/bereik': 945,\n",
       " '/c/af/bereken': 946,\n",
       " '/c/af/berekening': 947,\n",
       " '/c/af/bereklou': 948,\n",
       " '/c/af/berg': 949,\n",
       " '/c/af/bergbeklimmer': 950,\n",
       " '/c/af/berging': 951,\n",
       " '/c/af/bergketting': 952,\n",
       " '/c/af/bergpik': 953,\n",
       " '/c/af/bergreeks': 954,\n",
       " '/c/af/berig': 955,\n",
       " '/c/af/berillium': 956,\n",
       " '/c/af/berin': 957,\n",
       " '/c/af/berispe': 958,\n",
       " '/c/af/berk': 959,\n",
       " '/c/af/berkeboom': 960,\n",
       " '/c/af/berlyn': 961,\n",
       " '/c/af/berm': 962,\n",
       " '/c/af/beroemd': 963,\n",
       " '/c/af/beroemdheid': 964,\n",
       " '/c/af/beroep': 965,\n",
       " '/c/af/beroer': 966,\n",
       " '/c/af/beroerd': 967,\n",
       " '/c/af/beroerte': 968,\n",
       " '/c/af/berokken': 969,\n",
       " '/c/af/berooid': 970,\n",
       " '/c/af/besadig': 971,\n",
       " '/c/af/besef': 972,\n",
       " '/c/af/besem': 973,\n",
       " '/c/af/beset': 974,\n",
       " '/c/af/besete': 975,\n",
       " '/c/af/besetenheid': 976,\n",
       " '/c/af/beseël': 977,\n",
       " '/c/af/besiel': 978,\n",
       " '/c/af/besieling': 979,\n",
       " '/c/af/besien': 980,\n",
       " '/c/af/besinning': 981,\n",
       " '/c/af/besit': 982,\n",
       " '/c/af/besitting': 983,\n",
       " '/c/af/beskaaf': 984,\n",
       " '/c/af/beskadig': 985,\n",
       " '/c/af/beskadiging': 986,\n",
       " '/c/af/beskawe': 987,\n",
       " '/c/af/beskeid': 988,\n",
       " '/c/af/beskeie': 989,\n",
       " '/c/af/beskerm': 990,\n",
       " '/c/af/beskermfees': 991,\n",
       " '/c/af/beskermheer': 992,\n",
       " '/c/af/beskermheilige': 993,\n",
       " '/c/af/beskieting': 994,\n",
       " '/c/af/beskik': 995,\n",
       " '/c/af/beskikking': 996,\n",
       " '/c/af/beskinder': 997,\n",
       " '/c/af/beskonke': 998,\n",
       " '/c/af/beskuit': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'corpora': {'semeval-2016-2017-task3-subtaskBC': {'num_records': -1, 'record_format': 'dict', 'file_size': 6344358, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/semeval-2016-2017-task3-subtaskB-eng/__init__.py', 'license': 'All files released for the task are free for general research use', 'fields': {'2016-train': ['...'], '2016-dev': ['...'], '2017-test': ['...'], '2016-test': ['...']}, 'description': 'SemEval 2016 / 2017 Task 3 Subtask B and C datasets contain train+development (317 original questions, 3,169 related questions, and 31,690 comments), and test datasets in English. The description of the tasks and the collected data is given in sections 3 and 4.1 of the task paper http://alt.qcri.org/semeval2016/task3/data/uploads/semeval2016-task3-report.pdf linked in section “Papers” of https://github.com/RaRe-Technologies/gensim-data/issues/18.', 'checksum': '701ea67acd82e75f95e1d8e62fb0ad29', 'file_name': 'semeval-2016-2017-task3-subtaskBC.gz', 'read_more': ['http://alt.qcri.org/semeval2017/task3/', 'http://alt.qcri.org/semeval2017/task3/data/uploads/semeval2017-task3.pdf', 'https://github.com/RaRe-Technologies/gensim-data/issues/18', 'https://github.com/Witiko/semeval-2016_2017-task3-subtaskB-english'], 'parts': 1}, 'semeval-2016-2017-task3-subtaskA-unannotated': {'num_records': 189941, 'record_format': 'dict', 'file_size': 234373151, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/semeval-2016-2017-task3-subtaskA-unannotated-eng/__init__.py', 'license': 'These datasets are free for general research use.', 'fields': {'THREAD_SEQUENCE': '', 'RelQuestion': {'RELQ_CATEGORY': 'question category, according to the Qatar Living taxonomy', 'RELQ_DATE': 'date of posting', 'RELQ_ID': 'question indentifier', 'RELQ_USERID': 'identifier of the user asking the question', 'RELQ_USERNAME': 'name of the user asking the question', 'RelQBody': 'body of question', 'RelQSubject': 'subject of question'}, 'RelComments': [{'RelCText': 'text of answer', 'RELC_USERID': 'identifier of the user posting the comment', 'RELC_ID': 'comment identifier', 'RELC_USERNAME': 'name of the user posting the comment', 'RELC_DATE': 'date of posting'}]}, 'description': 'SemEval 2016 / 2017 Task 3 Subtask A unannotated dataset contains 189,941 questions and 1,894,456 comments in English collected from the Community Question Answering (CQA) web forum of Qatar Living. These can be used as a corpus for language modelling.', 'checksum': '2de0e2f2c4f91c66ae4fcf58d50ba816', 'file_name': 'semeval-2016-2017-task3-subtaskA-unannotated.gz', 'read_more': ['http://alt.qcri.org/semeval2016/task3/', 'http://alt.qcri.org/semeval2016/task3/data/uploads/semeval2016-task3-report.pdf', 'https://github.com/RaRe-Technologies/gensim-data/issues/18', 'https://github.com/Witiko/semeval-2016_2017-task3-subtaskA-unannotated-english'], 'parts': 1}, 'patent-2017': {'num_records': 353197, 'record_format': 'dict', 'file_size': 3087262469, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/patent-2017/__init__.py', 'license': 'not found', 'description': \"Patent Grant Full Text. Contains the full text including tables, sequence data and 'in-line' mathematical expressions of each patent grant issued in 2017.\", 'checksum-0': '818501f0b9af62d3b88294d86d509f8f', 'checksum-1': '66c05635c1d3c7a19b4a335829d09ffa', 'file_name': 'patent-2017.gz', 'read_more': ['http://patents.reedtech.com/pgrbft.php'], 'parts': 2}, 'quora-duplicate-questions': {'num_records': 404290, 'record_format': 'dict', 'file_size': 21684784, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/quora-duplicate-questions/__init__.py', 'license': 'probably https://www.quora.com/about/tos', 'fields': {'question1': 'the full text of each question', 'question2': 'the full text of each question', 'qid1': 'unique ids of each question', 'qid2': 'unique ids of each question', 'id': 'the id of a training set question pair', 'is_duplicate': 'the target variable, set to 1 if question1 and question2 have essentially the same meaning, and 0 otherwise'}, 'description': 'Over 400,000 lines of potential question duplicate pairs. Each line contains IDs for each question in the pair, the full text for each question, and a binary value that indicates whether the line contains a duplicate pair or not.', 'checksum': 'd7cfa7fbc6e2ec71ab74c495586c6365', 'file_name': 'quora-duplicate-questions.gz', 'read_more': ['https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs'], 'parts': 1}, 'wiki-english-20171001': {'num_records': 4924894, 'record_format': 'dict', 'file_size': 6516051717, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/wiki-english-20171001/__init__.py', 'license': 'https://dumps.wikimedia.org/legal.html', 'fields': {'section_texts': 'list of body of sections', 'section_titles': 'list of titles of sections', 'title': 'Title of wiki article'}, 'description': 'Extracted Wikipedia dump from October 2017. Produced by `python -m gensim.scripts.segment_wiki -f enwiki-20171001-pages-articles.xml.bz2 -o wiki-en.gz`', 'checksum-0': 'a7d7d7fd41ea7e2d7fa32ec1bb640d71', 'checksum-1': 'b2683e3356ffbca3b6c2dca6e9801f9f', 'checksum-2': 'c5cde2a9ae77b3c4ebce804f6df542c2', 'checksum-3': '00b71144ed5e3aeeb885de84f7452b81', 'file_name': 'wiki-english-20171001.gz', 'read_more': ['https://dumps.wikimedia.org/enwiki/20171001/'], 'parts': 4}, 'text8': {'num_records': 1701, 'record_format': 'list of str (tokens)', 'file_size': 33182058, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py', 'license': 'not found', 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.', 'checksum': '68799af40b6bda07dfa47a32612e5364', 'file_name': 'text8.gz', 'read_more': ['http://mattmahoney.net/dc/textdata.html'], 'parts': 1}, 'fake-news': {'num_records': 12999, 'record_format': 'dict', 'file_size': 20102776, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/fake-news/__init__.py', 'license': 'https://creativecommons.org/publicdomain/zero/1.0/', 'fields': {'crawled': 'date the story was archived', 'ord_in_thread': '', 'published': 'date published', 'participants_count': 'number of participants', 'shares': 'number of Facebook shares', 'replies_count': 'number of replies', 'main_img_url': 'image from story', 'spam_score': 'data from webhose.io', 'uuid': 'unique identifier', 'language': 'data from webhose.io', 'title': 'title of story', 'country': 'data from webhose.io', 'domain_rank': 'data from webhose.io', 'author': 'author of story', 'comments': 'number of Facebook comments', 'site_url': 'site URL from BS detector', 'text': 'text of story', 'thread_title': '', 'type': 'type of website (label from BS detector)', 'likes': 'number of Facebook likes'}, 'description': \"News dataset, contains text and metadata from 244 websites and represents 12,999 posts in total from a specific window of 30 days. The data was pulled using the webhose.io API, and because it's coming from their crawler, not all websites identified by their BS Detector are present in this dataset. Data sources that were missing a label were simply assigned a label of 'bs'. There are (ostensibly) no genuine, reliable, or trustworthy news sources represented in this dataset (so far), so don't trust anything you read.\", 'checksum': '5e64e942df13219465927f92dcefd5fe', 'file_name': 'fake-news.gz', 'read_more': ['https://www.kaggle.com/mrisdal/fake-news'], 'parts': 1}, '20-newsgroups': {'num_records': 18846, 'record_format': 'dict', 'file_size': 14483581, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/20-newsgroups/__init__.py', 'license': 'not found', 'fields': {'topic': 'name of topic (20 variant of possible values)', 'set': \"marker of original split (possible values 'train' and 'test')\", 'data': '', 'id': 'original id inferred from folder name'}, 'description': 'The notorious collection of approximately 20,000 newsgroup posts, partitioned (nearly) evenly across 20 different newsgroups.', 'checksum': 'c92fd4f6640a86d5ba89eaad818a9891', 'file_name': '20-newsgroups.gz', 'read_more': ['http://qwone.com/~jason/20Newsgroups/'], 'parts': 1}, '__testing_matrix-synopsis': {'description': '[THIS IS ONLY FOR TESTING] Synopsis of the movie matrix.', 'checksum': '1767ac93a089b43899d54944b07d9dc5', 'file_name': '__testing_matrix-synopsis.gz', 'read_more': ['http://www.imdb.com/title/tt0133093/plotsummary?ref_=ttpl_pl_syn#synopsis'], 'parts': 1}, '__testing_multipart-matrix-synopsis': {'description': '[THIS IS ONLY FOR TESTING] Synopsis of the movie matrix.', 'checksum-0': 'c8b0c7d8cf562b1b632c262a173ac338', 'checksum-1': '5ff7fc6818e9a5d9bc1cf12c35ed8b96', 'checksum-2': '966db9d274d125beaac7987202076cba', 'file_name': '__testing_multipart-matrix-synopsis.gz', 'read_more': ['http://www.imdb.com/title/tt0133093/plotsummary?ref_=ttpl_pl_syn#synopsis'], 'parts': 3}}, 'models': {'fasttext-wiki-news-subwords-300': {'num_records': 999999, 'file_size': 1005007116, 'base_dataset': 'Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/fasttext-wiki-news-subwords-300/__init__.py', 'license': 'https://creativecommons.org/licenses/by-sa/3.0/', 'parameters': {'dimension': 300}, 'description': '1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).', 'read_more': ['https://fasttext.cc/docs/en/english-vectors.html', 'https://arxiv.org/abs/1712.09405', 'https://arxiv.org/abs/1607.01759'], 'checksum': 'de2bb3a20c46ce65c9c131e1ad9a77af', 'file_name': 'fasttext-wiki-news-subwords-300.gz', 'parts': 1}, 'conceptnet-numberbatch-17-06-300': {'num_records': 1917247, 'file_size': 1225497562, 'base_dataset': 'ConceptNet, word2vec, GloVe, and OpenSubtitles 2016', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/conceptnet-numberbatch-17-06-300/__init__.py', 'license': 'https://github.com/commonsense/conceptnet-numberbatch/blob/master/LICENSE.txt', 'parameters': {'dimension': 300}, 'description': 'ConceptNet Numberbatch consists of state-of-the-art semantic vectors (also known as word embeddings) that can be used directly as a representation of word meanings or as a starting point for further machine learning. ConceptNet Numberbatch is part of the ConceptNet open data project. ConceptNet provides lots of ways to compute with word meanings, one of which is word embeddings. ConceptNet Numberbatch is a snapshot of just the word embeddings. It is built using an ensemble that combines data from ConceptNet, word2vec, GloVe, and OpenSubtitles 2016, using a variation on retrofitting.', 'read_more': ['http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972', 'https://github.com/commonsense/conceptnet-numberbatch', 'http://conceptnet.io/'], 'checksum': 'fd642d457adcd0ea94da0cd21b150847', 'file_name': 'conceptnet-numberbatch-17-06-300.gz', 'parts': 1}, 'word2vec-ruscorpora-300': {'num_records': 184973, 'file_size': 208427381, 'base_dataset': 'Russian National Corpus (about 250M words)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-ruscorpora-300/__init__.py', 'license': 'https://creativecommons.org/licenses/by/4.0/deed.en', 'parameters': {'dimension': 300, 'window_size': 10}, 'description': 'Word2vec Continuous Skipgram vectors trained on full Russian National Corpus (about 250M words). The model contains 185K words.', 'preprocessing': 'The corpus was lemmatized and tagged with Universal PoS', 'read_more': ['https://www.academia.edu/24306935/WebVectors_a_Toolkit_for_Building_Web_Interfaces_for_Vector_Semantic_Models', 'http://rusvectores.org/en/', 'https://github.com/RaRe-Technologies/gensim-data/issues/3'], 'checksum': '9bdebdc8ae6d17d20839dd9b5af10bc4', 'file_name': 'word2vec-ruscorpora-300.gz', 'parts': 1}, 'word2vec-google-news-300': {'num_records': 3000000, 'file_size': 1743563840, 'base_dataset': 'Google News (about 100 billion words)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-google-news-300/__init__.py', 'license': 'not found', 'parameters': {'dimension': 300}, 'description': \"Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. The phrases were obtained using a simple data-driven approach described in 'Distributed Representations of Words and Phrases and their Compositionality' (https://code.google.com/archive/p/word2vec/).\", 'read_more': ['https://code.google.com/archive/p/word2vec/', 'https://arxiv.org/abs/1301.3781', 'https://arxiv.org/abs/1310.4546', 'https://www.microsoft.com/en-us/research/publication/linguistic-regularities-in-continuous-space-word-representations/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F189726%2Frvecs.pdf'], 'checksum': 'a5e5354d40acb95f9ec66d5977d140ef', 'file_name': 'word2vec-google-news-300.gz', 'parts': 1}, 'glove-wiki-gigaword-50': {'num_records': 400000, 'file_size': 69182535, 'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-50/__init__.py', 'license': 'http://opendatacommons.org/licenses/pddl/', 'parameters': {'dimension': 50}, 'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).', 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-50.txt`.', 'read_more': ['https://nlp.stanford.edu/projects/glove/', 'https://nlp.stanford.edu/pubs/glove.pdf'], 'checksum': 'c289bc5d7f2f02c6dc9f2f9b67641813', 'file_name': 'glove-wiki-gigaword-50.gz', 'parts': 1}, 'glove-wiki-gigaword-100': {'num_records': 400000, 'file_size': 134300434, 'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-100/__init__.py', 'license': 'http://opendatacommons.org/licenses/pddl/', 'parameters': {'dimension': 100}, 'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).', 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-100.txt`.', 'read_more': ['https://nlp.stanford.edu/projects/glove/', 'https://nlp.stanford.edu/pubs/glove.pdf'], 'checksum': '40ec481866001177b8cd4cb0df92924f', 'file_name': 'glove-wiki-gigaword-100.gz', 'parts': 1}, 'glove-wiki-gigaword-200': {'num_records': 400000, 'file_size': 264336934, 'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-200/__init__.py', 'license': 'http://opendatacommons.org/licenses/pddl/', 'parameters': {'dimension': 200}, 'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).', 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-200.txt`.', 'read_more': ['https://nlp.stanford.edu/projects/glove/', 'https://nlp.stanford.edu/pubs/glove.pdf'], 'checksum': '59652db361b7a87ee73834a6c391dfc1', 'file_name': 'glove-wiki-gigaword-200.gz', 'parts': 1}, 'glove-wiki-gigaword-300': {'num_records': 400000, 'file_size': 394362229, 'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-300/__init__.py', 'license': 'http://opendatacommons.org/licenses/pddl/', 'parameters': {'dimension': 300}, 'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).', 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-300.txt`.', 'read_more': ['https://nlp.stanford.edu/projects/glove/', 'https://nlp.stanford.edu/pubs/glove.pdf'], 'checksum': '29e9329ac2241937d55b852e8284e89b', 'file_name': 'glove-wiki-gigaword-300.gz', 'parts': 1}, 'glove-twitter-25': {'num_records': 1193514, 'file_size': 109885004, 'base_dataset': 'Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-25/__init__.py', 'license': 'http://opendatacommons.org/licenses/pddl/', 'parameters': {'dimension': 25}, 'description': 'Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).', 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-25.txt`.', 'read_more': ['https://nlp.stanford.edu/projects/glove/', 'https://nlp.stanford.edu/pubs/glove.pdf'], 'checksum': '50db0211d7e7a2dcd362c6b774762793', 'file_name': 'glove-twitter-25.gz', 'parts': 1}, 'glove-twitter-50': {'num_records': 1193514, 'file_size': 209216938, 'base_dataset': 'Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-50/__init__.py', 'license': 'http://opendatacommons.org/licenses/pddl/', 'parameters': {'dimension': 50}, 'description': 'Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/)', 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-50.txt`.', 'read_more': ['https://nlp.stanford.edu/projects/glove/', 'https://nlp.stanford.edu/pubs/glove.pdf'], 'checksum': 'c168f18641f8c8a00fe30984c4799b2b', 'file_name': 'glove-twitter-50.gz', 'parts': 1}, 'glove-twitter-100': {'num_records': 1193514, 'file_size': 405932991, 'base_dataset': 'Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-100/__init__.py', 'license': 'http://opendatacommons.org/licenses/pddl/', 'parameters': {'dimension': 100}, 'description': 'Pre-trained vectors based on  2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/)', 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-100.txt`.', 'read_more': ['https://nlp.stanford.edu/projects/glove/', 'https://nlp.stanford.edu/pubs/glove.pdf'], 'checksum': 'b04f7bed38756d64cf55b58ce7e97b15', 'file_name': 'glove-twitter-100.gz', 'parts': 1}, 'glove-twitter-200': {'num_records': 1193514, 'file_size': 795373100, 'base_dataset': 'Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)', 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-200/__init__.py', 'license': 'http://opendatacommons.org/licenses/pddl/', 'parameters': {'dimension': 200}, 'description': 'Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).', 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-200.txt`.', 'read_more': ['https://nlp.stanford.edu/projects/glove/', 'https://nlp.stanford.edu/pubs/glove.pdf'], 'checksum': 'e52e8392d1860b95d5308a525817d8f9', 'file_name': 'glove-twitter-200.gz', 'parts': 1}, '__testing_word2vec-matrix-synopsis': {'description': '[THIS IS ONLY FOR TESTING] Word vecrors of the movie matrix.', 'parameters': {'dimensions': 50}, 'preprocessing': 'Converted to w2v using a preprocessed corpus. Converted to w2v format with `python3.5 -m gensim.models.word2vec -train <input_filename> -iter 50 -output <output_filename>`.', 'read_more': [], 'checksum': '534dcb8b56a360977a269b7bfc62d124', 'file_name': '__testing_word2vec-matrix-synopsis.gz', 'parts': 1}}}\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "print(api.info())  # This will list available pre-trained models like Word2Vec, GloVe, FastText, etc.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
